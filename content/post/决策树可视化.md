---
title: "机器学习-决策树-可视化01
"
date: 2018-05-12T18:16:59+08:00
draft: True
tags: ["python","机器学习","可视化"]
share: true
---

这是关于如何对决策树分类器结果可视化的指导。
<!--more-->


## <center>决策树结果的可视化-python

### 一、对于sklearn中的tree模型可视化  
1、图形结果输出pdf保存本地；  
2、图形结果显示在界面

#### 1、图形结果输出pdf保存本地


```python
from sklearn.datasets import load_iris
import graphviz 
from sklearn import tree

iris = load_iris()
clf = tree.DecisionTreeClassifier()
clf = clf.fit(iris.data, iris.target)
dot_data = tree.export_graphviz(clf, out_file=None) 
graph = graphviz.Source(dot_data) 
graph.render("保存的名字")
```

#### 2、图形结果显示在界面


```python
from sklearn.datasets import load_iris
import graphviz 
from sklearn import tree

iris = load_iris()
clf = tree.DecisionTreeClassifier()
clf = clf.fit(iris.data, iris.target)

# 首先生成graphvis所需的dot数据
dot_data = tree.export_graphviz(clf, # 已经训练的模型
                                out_file=None, # dot文件输出名称，默认tree.dot
                                 feature_names=iris.feature_names,  # 特征变量名称
                                 class_names=iris.target_names,  # 目标变量名称
                                 filled=False, # 颜色是否填充，默认False-不填充
                                rounded=True,  # 字体设置，默认False
                                 special_characters=False  # postgript对特殊字符处理，默认false
                               )  

# 将dot数据通过graphviz渲染
graph = graphviz.Source(dot_data)

# 界面上直接显示
graph

# 将图表保存本地为pdf（默认即为pdf）。？？如何保存为png
graph.render('new2')
```




    'new2.pdf'



### 二、对于xgboost的训练结果。  
1、tree图形结果输出pdf保存本地；  
2、tree图形结果显示在界面；  
3、特征的重要性可视化。  
　　tree结果可以采用两种方式，①xgboost包中的plot_tree函数、②借助xgboost的to_graghviz和graphviz包  
　　特征重要新可视化，两种方式①xgboost包中的plot_importance函数、②自定义函数

#### 1、tree图形结果可视化①

> from xgboost import plot_tree  
plot_tree(my_module)  my_module  # 已经fit

#### 1、tree图形结果可视化②


```python
from xgboost import to_graphviz
import graphviz

# my_module  # 已经fit
dot_data = to_graphviz(my_module)
graph = graphviz.Source(dot_data) 

# 显示在桌面
graph

# 保存到本地
graph.render('new2')
```

#### 2、特征重要新可视化①

> from xgboost import plot_importance  
plot_importance(booster=my_module, importance_type='weight')  # my_module  # 已经fit

#### 2、特征重要新可视化②


```python
def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):
    '''
    该函数方法借鉴tune parameter...大神的，改写而来
    alg: 模型
    dtrain: pd.DataFrame,包含训练特征和目标特征
    predictors: list，包含训练特征的名称
    performCV: 按默认
    printFeatureImportance: 按默认
    '''
    
    #Fit the algorithm on the data
    alg.fit(dtrain[predictors], dtrain['Survived'])
        
    #Predict training set:
    dtrain_predictions = alg.predict(dtrain[predictors])
    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]
    
    #Perform cross-validation:
    if performCV:
        cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain['Survived'], cv=cv_folds, scoring='roc_auc')
    
    #Print model report:
    print ("\nModel Report")
    print ("Accuracy : %.4g" % metrics.accuracy_score(dtrain['Survived'].values, dtrain_predictions))
    print ("AUC Score (Train): %f" % metrics.roc_auc_score(dtrain['Survived'], dtrain_predprob))
    
    if performCV:
        print ("CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))
        
    #Print Feature Importance:
    if printFeatureImportance:
        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)
        feat_imp.plot(kind='bar', title='Feature Importances')
        plt.ylabel('Feature Importance Score')
```

参考:  
1. How to Visualize Gradient Boosting Decision Trees With XGBoost in Python https://machinelearningmastery.com/visualize-gradient-boosting-decision-trees-xgboost-python/
2. graphviz官方 https://pypi.org/project/graphviz/
3.  XGBoost Plotting API以及GBDT组合特征实践 https://blog.csdn.net/sb19931201/article/details/65445514
4. sklearn官方 http://scikit-learn.org/stable/modules/tree.html#tree

